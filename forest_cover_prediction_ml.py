# -*- coding: utf-8 -*-
"""forest-cover-prediction-ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NPdweEyEZjq8oO2eE2c_ROpohsWfCIJ0
"""

# Import the pandas library to handle data
import pandas as pd

# Read the dataset from a CSV file named 'train.csv'
df = pd.read_csv('train.csv')

# Show the first 5 rows of the dataset to get an initial look
df.head()

# Display concise summary of the DataFrame, including data types and non-null values
df.info()

# Count the occurrences of each class in the 'Cover_Type' column
df['Cover_Type'].value_counts()

# Check for missing values in the dataset
df.isnull().sum()

# Display the shape (number of rows and columns) of the dataset
df.shape

# Check if there are any duplicated rows in the dataset
df.duplicated().sum()

# Separate the feature set (X) and the target variable (y)
X = df.drop('Cover_Type', axis=1)
y = df['Cover_Type']

"""Split Data into Training and Test Sets"""

# Import the train_test_split function to divide the dataset into training and test sets
from sklearn.model_selection import train_test_split

# Split the data into 80% training and 20% test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Show the shape of the training feature set
X_train.shape

# Show the shape of the test feature set
X_test.shape

"""Logistic Regression Model"""

# Import LogisticRegression and accuracy_score to build a logistic regression model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Instantiate the Logistic Regression model
lg = LogisticRegression()

# Train the Logistic Regression model on the training set
lg.fit(X_train, y_train)

# Predict the target variable for the test set using Logistic Regression
ypred = lg.predict(X_test)

# Calculate the accuracy of the Logistic Regression model
accuracy_score(y_test, ypred)

"""Decision Tree Model"""

# Import DecisionTreeClassifier to build a Decision Tree model
from sklearn.tree import DecisionTreeClassifier

# Instantiate the Decision Tree Classifier model
dtc = DecisionTreeClassifier()

# Train the Decision Tree model on the training set
dtc.fit(X_train, y_train)

# Predict the target variable for the test set using Decision Tree
ypred = dtc.predict(X_test)

# Calculate the accuracy of the Decision Tree model
accuracy_score(y_test, ypred)

# Import RandomForestClassifier to build a Random Forest model
from sklearn.ensemble import RandomForestClassifier

# Instantiate the Random Forest Classifier model
rfc = RandomForestClassifier()

# Train the Random Forest model on the training set
rfc.fit(X_train, y_train)

# Predict the target variable for the test set using Random Forest
ypred = rfc.predict(X_test)

# Calculate the accuracy of the Random Forest model
accuracy_score(y_test, ypred)

# Input values for a new prediction (manually defined example data)
input_values = (101, 2998, 45, 8, 351, 16, 5842, 223, 222, 134, 3721,
                1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

# Import numpy to handle arrays
import numpy as np

# Convert the input values to a numpy array for prediction
features = np.array([input_values])

# Predict the class for the new input data using the Random Forest model
rfc.predict(features).reshape(1, -1)

# Import pickle to save the trained Random Forest model
import pickle

# Save the Random Forest model to a file named 'rfc.pkl'
pickle.dump(rfc, open('rfc.pkl', 'wb'))